

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>stransfer.network &mdash; StyleTransfer  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> StyleTransfer
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Modules:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../terminal_interface.html">Terminal Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../network_module.html">Network Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dataset_module.html">Dataset Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../img_utils.html">Image Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../logging_module.html">Logging Module</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">StyleTransfer</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>stransfer.network</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for stransfer.network</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This module holds the implementation of all the networks, their losses, and</span>
<span class="sd">their components</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">shutil</span>

<span class="kn">import</span> <span class="nn">imageio</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="k">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">tensorboardX</span> <span class="k">import</span> <span class="n">SummaryWriter</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="k">import</span> <span class="n">tqdm</span>

<span class="kn">from</span> <span class="nn">stransfer</span> <span class="k">import</span> <span class="n">c_logging</span><span class="p">,</span> <span class="n">constants</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">img_utils</span>

<span class="n">LOGGER</span> <span class="o">=</span> <span class="n">c_logging</span><span class="o">.</span><span class="n">get_logger</span><span class="p">()</span>


<div class="viewcode-block" id="get_tensorboard_writer"><a class="viewcode-back" href="../../network_module.html#stransfer.network.get_tensorboard_writer">[docs]</a><span class="k">def</span> <span class="nf">get_tensorboard_writer</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SummaryWriter</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a TensorBoard writer at the folder with `path`.</span>

<span class="sd">    If `path` exists then it is deleted and recreated.</span>

<span class="sd">    :param path: the path where our SummaryWriter will write</span>
<span class="sd">    :return: an initialized SummaryWriter</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">ignore_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></div>


<div class="viewcode-block" id="adaptive_torch_load"><a class="viewcode-back" href="../../network_module.html#stransfer.network.adaptive_torch_load">[docs]</a><span class="k">def</span> <span class="nf">adaptive_torch_load</span><span class="p">(</span><span class="n">weights_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    When loading saved weights, we check if need to map them to</span>
<span class="sd">    either `cuda` or `cpu`.</span>

<span class="sd">    :param weights_path: paths of the weights to load</span>
<span class="sd">    :return: the loaded weights</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">constants</span><span class="o">.</span><span class="n">DEVICE</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weights_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weights_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_load_latest_model_weigths</span><span class="p">(</span><span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                               <span class="n">style_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                               <span class="n">models_path</span><span class="o">=</span><span class="s1">&#39;data/models/&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    :param models_path: path where the pretrained models are saved</span>
<span class="sd">    :return: the weights file for the latest epoch corresponding</span>
<span class="sd">        to the model and style specified.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">models_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">constants</span><span class="o">.</span><span class="n">PROJECT_ROOT_PATH</span><span class="p">,</span> <span class="n">models_path</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">latest_weight_name</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">models_path</span><span class="p">)</span>
                                     <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span> <span class="ow">and</span>
                                     <span class="n">style_name</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>
        <span class="n">LOGGER</span><span class="o">.</span><span class="n">critical</span><span class="p">(</span><span class="s1">&#39;There are no weights for the specified model name (</span><span class="si">%s</span><span class="s1">) &#39;</span>
                        <span class="s1">&#39;and style (</span><span class="si">%s</span><span class="s1">). In the specified path: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span>
                        <span class="n">model_name</span><span class="p">,</span> <span class="n">style_name</span><span class="p">,</span> <span class="n">models_path</span><span class="p">)</span>

        <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="s1">&#39;There are no weights for the specified &#39;</span>
                             <span class="s1">&#39;model name and style.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">adaptive_torch_load</span><span class="p">(</span><span class="n">models_path</span> <span class="o">+</span> <span class="n">latest_weight_name</span><span class="p">)</span>


<div class="viewcode-block" id="StyleLoss"><a class="viewcode-back" href="../../network_module.html#stransfer.network.StyleLoss">[docs]</a><span class="k">class</span> <span class="nc">StyleLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implementation of the style loss</span>

<span class="sd">    :param target: the tensor representing the style image we want to</span>
<span class="sd">        take as reference during training</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_target</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>

<div class="viewcode-block" id="StyleLoss.gram_matrix"><a class="viewcode-back" href="../../network_module.html#stransfer.network.StyleLoss.gram_matrix">[docs]</a>    <span class="k">def</span> <span class="nf">gram_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the gram matrix for the `input` tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># The size would be [batch_size, depth, height, width]</span>
        <span class="n">bs</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>

        <span class="n">features</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">height</span> <span class="o">*</span> <span class="n">width</span><span class="p">)</span>
        <span class="n">features_t</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># compute the gram product</span>
        <span class="n">G</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">features_t</span><span class="p">)</span>

        <span class="c1"># we &#39;normalize&#39; the values of the gram matrix</span>
        <span class="c1"># by dividing by the number of element in each feature maps.</span>
        <span class="k">return</span> <span class="n">G</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">depth</span> <span class="o">*</span> <span class="n">height</span> <span class="o">*</span> <span class="n">width</span><span class="p">)</span></div>

<div class="viewcode-block" id="StyleLoss.forward"><a class="viewcode-back" href="../../network_module.html#stransfer.network.StyleLoss.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compare the gram matrix of the `input` with that of the `target`.</span>
<span class="sd">        By doing this we calculate the style loss, which is saved to a local</span>
<span class="sd">        `loss` attribute.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">G</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gram_matrix</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">G</span><span class="p">,</span>
                               <span class="c1"># correct the fact that we only have one</span>
                               <span class="c1"># style image for the whole batch</span>
                               <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">G</span><span class="p">))</span>

        <span class="k">return</span> <span class="nb">input</span></div>

<div class="viewcode-block" id="StyleLoss.set_target"><a class="viewcode-back" href="../../network_module.html#stransfer.network.StyleLoss.set_target">[docs]</a>    <span class="k">def</span> <span class="nf">set_target</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method allows us to change the style target of the loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Here the target is the conv layer which we&#39;re taking as reference</span>
        <span class="c1"># as the style source</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gram_matrix</span><span class="p">(</span><span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span></div></div>


<div class="viewcode-block" id="ContentLoss"><a class="viewcode-back" href="../../network_module.html#stransfer.network.ContentLoss">[docs]</a><span class="k">class</span> <span class="nc">ContentLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implementation of the content loss</span>

<span class="sd">    :param target: the target image we want to use to calculate the content</span>
<span class="sd">        loss</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Here the target is the conv layer which we&#39;re taking as reference</span>
        <span class="c1"># as the content source</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_target</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>

<div class="viewcode-block" id="ContentLoss.set_target"><a class="viewcode-back" href="../../network_module.html#stransfer.network.ContentLoss.set_target">[docs]</a>    <span class="k">def</span> <span class="nf">set_target</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method allows us to set the target image of this content loss instance</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span></div>

<div class="viewcode-block" id="ContentLoss.forward"><a class="viewcode-back" href="../../network_module.html#stransfer.network.ContentLoss.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the distance between the `input` image and the `target`.</span>
<span class="sd">        This is saved to a local `loss` attribute.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Content loss is just the per pixel distance between an input and</span>
        <span class="c1"># the target</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">input</span></div></div>


<div class="viewcode-block" id="FeatureReconstructionLoss"><a class="viewcode-back" href="../../network_module.html#stransfer.network.FeatureReconstructionLoss">[docs]</a><span class="k">class</span> <span class="nc">FeatureReconstructionLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implementation of the feature reconstruction loss.</span>

<span class="sd">    ..note::</span>
<span class="sd">        this loss is currently not used since it doesn&#39;t seem</span>
<span class="sd">        to provide much improvement over the normal :class:`.ContentLoss`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Here the target is the conv layer which we&#39;re taking as reference</span>
        <span class="c1"># as the content source</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_target</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_target</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

<div class="viewcode-block" id="FeatureReconstructionLoss.forward"><a class="viewcode-back" href="../../network_module.html#stransfer.network.FeatureReconstructionLoss.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the feature loss of `input` with respect to the `target`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Content loss is just the per pixel distance between an input and</span>
        <span class="c1"># the target</span>
        <span class="n">l2_norm</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
        <span class="n">l2_squared</span> <span class="o">=</span> <span class="n">l2_norm</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># The size would be [batch_size, depth, height, width]</span>
        <span class="n">bs</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">l2_squared</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">bs</span> <span class="o">*</span> <span class="n">depth</span> <span class="o">*</span> <span class="n">height</span> <span class="o">*</span> <span class="n">width</span><span class="p">)</span>

        <span class="k">return</span> <span class="nb">input</span></div></div>


<div class="viewcode-block" id="StyleNetwork"><a class="viewcode-back" href="../../network_module.html#stransfer.network.StyleNetwork">[docs]</a><span class="k">class</span> <span class="nc">StyleNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implementation of the StyleNetwork as defined in</span>

<span class="sd">    `A Neural Algorithm of Artistic Style - Gatys (2015) &lt;https://arxiv.org/abs/1508.06576&gt;`_</span>

<span class="sd">    :param style_image: tensor of the image we want to use as a source for the style</span>
<span class="sd">    :param content_image: tensor of the image we want to use as the source for the content</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">content_layers</span> <span class="o">=</span> <span class="p">[</span>  <span class="c1"># layers from where image content will be taken</span>
        <span class="c1">#  &#39;Conv2d_1&#39;,</span>
        <span class="c1">#  &#39;Conv2d_2&#39;,</span>
        <span class="c1">#  &#39;Conv2d_3&#39;,</span>
        <span class="s1">&#39;Conv2d_4&#39;</span><span class="p">,</span>
        <span class="c1">#  &#39;Conv2d_5&#39;,</span>
    <span class="p">]</span>

    <span class="n">style_layers</span> <span class="o">=</span> <span class="p">[</span>  <span class="c1"># layers were the image style will be taken from</span>
        <span class="s1">&#39;Conv2d_1&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Conv2d_2&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Conv2d_3&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Conv2d_4&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Conv2d_5&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="n">feature_loss_layers</span> <span class="o">=</span> <span class="p">[</span>  <span class="c1"># layer for the feature loss</span>
        <span class="s1">&#39;ReLU_4&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">style_image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">content_image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">content_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">style_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_losses</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="n">content_image</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># set a dummy content image</span>
            <span class="n">content_image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span>

        <span class="c1"># we use the vgg19 net to get the losses during training</span>
        <span class="n">vgg</span> <span class="o">=</span> <span class="p">(</span><span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">vgg19</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

               <span class="c1"># we only want the `features` part of VGG19 (see print(vgg) for structure)</span>
               <span class="o">.</span><span class="n">features</span>

               <span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">constants</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
               <span class="o">.</span><span class="n">eval</span><span class="p">())</span>  <span class="c1"># by default we set the network to evaluation mode</span>

        <span class="c1"># separate the network in pieces. These are limited by the layers</span>
        <span class="c1"># specified in the `content_layers`, `style_layers`, and `feature_loss_layers`</span>
        <span class="c1"># Each piece is basically a sequential network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net_pieces</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="p">]</span>

        <span class="n">loss_added</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">current_piece</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">vgg</span><span class="p">:</span>
            <span class="c1"># for each layer in VGG, simply add it to the sequential net corresponding</span>
            <span class="c1"># to the layer we&#39;re currently working on (and give it an appropriate name)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">):</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">inplace</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="c1"># one of {&#39;Conv2d&#39;, &#39;MaxPool2d&#39;, &#39;ReLU&#39;}</span>
            <span class="n">layer_name</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="n">f</span><span class="s2">&quot;_</span><span class="si">{i}</span><span class="s2">&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">net_pieces</span><span class="p">[</span><span class="n">current_piece</span><span class="p">]</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">layer_name</span><span class="p">,</span> <span class="n">layer</span><span class="p">)</span>

            <span class="c1"># if the layer is used to calculate the content, style, or feature losses then:</span>
            <span class="c1"># Save in the appropriate list the &#39;pointer&#39; to the loss and the piece where</span>
            <span class="c1"># it belongs</span>
            <span class="k">if</span> <span class="n">layer_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">content_layers</span><span class="p">:</span>
                <span class="c1"># output of passing the `content_image` through all layers we&#39;ve</span>
                <span class="c1"># processed until now</span>
                <span class="n">layer_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_through_pieces</span><span class="p">(</span><span class="n">content_image</span><span class="p">)</span>

                <span class="c1"># calculate content loss</span>
                <span class="n">content_loss</span> <span class="o">=</span> <span class="n">ContentLoss</span><span class="p">(</span><span class="n">layer_output</span><span class="p">)</span>

                <span class="c1"># save pointer to content loss in `self.content_losses` together</span>
                <span class="c1"># with the INDEX of the piece to which it corresponds</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">content_losses</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">content_loss</span><span class="p">,</span> <span class="n">current_piece</span><span class="p">])</span>

                <span class="c1"># finally, say that a loss has been added so that the next iteration we</span>
                <span class="c1"># start with a new network piece</span>
                <span class="n">loss_added</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="c1"># same is to be done for the style and feature losses</span>
            <span class="k">if</span> <span class="n">layer_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">style_layers</span><span class="p">:</span>
                <span class="n">layer_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_through_pieces</span><span class="p">(</span><span class="n">style_image</span><span class="p">)</span>
                <span class="n">style_loss</span> <span class="o">=</span> <span class="n">StyleLoss</span><span class="p">(</span><span class="n">layer_output</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">style_losses</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">style_loss</span><span class="p">,</span> <span class="n">current_piece</span><span class="p">])</span>
                <span class="n">loss_added</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="k">if</span> <span class="n">layer_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_loss_layers</span><span class="p">:</span>
                <span class="n">layer_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_through_pieces</span><span class="p">(</span><span class="n">content_image</span><span class="p">)</span>
                <span class="n">feature_loss</span> <span class="o">=</span> <span class="n">FeatureReconstructionLoss</span><span class="p">(</span><span class="n">layer_output</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">feature_losses</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">feature_loss</span><span class="p">,</span> <span class="n">current_piece</span><span class="p">])</span>
                <span class="n">loss_added</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="c1"># If a loss has been added for the current layer then we say</span>
            <span class="c1"># that we&#39;re now working on a different piece</span>
            <span class="k">if</span> <span class="n">loss_added</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">net_pieces</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">())</span>
                <span class="n">current_piece</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">loss_added</span> <span class="o">=</span> <span class="kc">False</span>

<div class="viewcode-block" id="StyleNetwork.run_through_pieces"><a class="viewcode-back" href="../../network_module.html#stransfer.network.StyleNetwork.run_through_pieces">[docs]</a>    <span class="k">def</span> <span class="nf">run_through_pieces</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_g</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">until</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runs ths input `input_g` through all the pieces of the network, or until the</span>
<span class="sd">        specified layer if `until` is not `-1`</span>

<span class="sd">        :param input_g: the input to run through the network</span>
<span class="sd">        :param until: by default `-1`. If changed then it specified until which layer</span>
<span class="sd">            we want to run the input through</span>
<span class="sd">        :return: the output of running the input through all the specified layers</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">input_g</span>

        <span class="c1"># if no array of pieces is provided then we just run the input</span>
        <span class="c1"># through all pieces in the network</span>
        <span class="k">if</span> <span class="n">until</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">pieces</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net_pieces</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">pieces</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net_pieces</span><span class="p">[:</span><span class="n">until</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>

        <span class="c1"># finally run the input image through the pieces</span>
        <span class="k">for</span> <span class="n">piece</span> <span class="ow">in</span> <span class="n">pieces</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">piece</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span></div>

<div class="viewcode-block" id="StyleNetwork.get_total_current_content_loss"><a class="viewcode-back" href="../../network_module.html#stransfer.network.StyleNetwork.get_total_current_content_loss">[docs]</a>    <span class="k">def</span> <span class="nf">get_total_current_content_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the sum of all the `loss` present in all</span>
<span class="sd">        *content* nodes</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">loss</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">content_losses</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span></div>

<div class="viewcode-block" id="StyleNetwork.get_total_current_feature_loss"><a class="viewcode-back" href="../../network_module.html#stransfer.network.StyleNetwork.get_total_current_feature_loss">[docs]</a>    <span class="k">def</span> <span class="nf">get_total_current_feature_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the sum of all the `loss` present in all</span>
<span class="sd">        *content* nodes</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">loss</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_losses</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span></div>

<div class="viewcode-block" id="StyleNetwork.get_total_current_style_loss"><a class="viewcode-back" href="../../network_module.html#stransfer.network.StyleNetwork.get_total_current_style_loss">[docs]</a>    <span class="k">def</span> <span class="nf">get_total_current_style_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the sum of all the `loss` present in all</span>
<span class="sd">        *style* nodes</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">loss</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">style_losses</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span></div>

<div class="viewcode-block" id="StyleNetwork.forward"><a class="viewcode-back" href="../../network_module.html#stransfer.network.StyleNetwork.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">content_image</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">style_image</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given an input image pass it through all layers in the network</span>

<span class="sd">        :param input_image: the image to pass through the network</span>
<span class="sd">        :param content_image: if specified then this will change the curret target</span>
<span class="sd">            for the content loss</span>
<span class="sd">        :param style_image: if specified then this will change the current target</span>
<span class="sd">            for the style loss</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># first set content, feature, and style targets</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">piece_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">content_losses</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_losses</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">content_image</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">set_target</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">run_through_pieces</span><span class="p">(</span><span class="n">content_image</span><span class="p">,</span> <span class="n">piece_idx</span><span class="p">)</span>
                <span class="p">)</span>

            <span class="n">loss</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">run_through_pieces</span><span class="p">(</span><span class="n">input_image</span><span class="p">,</span> <span class="n">piece_idx</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># if we provide a style image to override the one</span>
        <span class="c1"># provided in the __init__</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">piece_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">style_losses</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">style_image</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">set_target</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">run_through_pieces</span><span class="p">(</span><span class="n">content_image</span><span class="p">,</span> <span class="n">piece_idx</span><span class="p">)</span>
                <span class="p">)</span>

            <span class="n">loss</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">run_through_pieces</span><span class="p">(</span><span class="n">input_image</span><span class="p">,</span> <span class="n">piece_idx</span><span class="p">)</span>
            <span class="p">)</span></div>

        <span class="c1"># we don&#39;t need the network output, so there is no need to run</span>
        <span class="c1"># the input through the whole network</span>

    <span class="k">def</span> <span class="nf">get_content_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_img</span><span class="p">,</span> <span class="n">optt</span><span class="o">=</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">):</span>
        <span class="c1"># we want to apply the gradient to the content image, so we</span>
        <span class="c1"># need to mark it as such</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optt</span><span class="p">([</span><span class="n">input_img</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()])</span>

        <span class="k">return</span> <span class="n">optimizer</span>

<div class="viewcode-block" id="StyleNetwork.train_gatys"><a class="viewcode-back" href="../../network_module.html#stransfer.network.StyleNetwork.train_gatys">[docs]</a>    <span class="k">def</span> <span class="nf">train_gatys</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">style_image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                    <span class="n">content_image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                    <span class="n">steps</span><span class="o">=</span><span class="mi">550</span><span class="p">,</span>
                    <span class="n">style_weight</span><span class="o">=</span><span class="mi">100_000</span><span class="p">,</span>
                    <span class="n">content_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates a new image with the style of `style_image` and the content</span>
<span class="sd">        of `content_image`</span>

<span class="sd">        :return: the converted image</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">style_image</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">),</span> <span class="s1">&#39;Images need to be already loaded&#39;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">content_image</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">),</span> <span class="s1">&#39;Images need to be already loaded&#39;</span>

        <span class="c1"># start from content image</span>
        <span class="n">input_image</span> <span class="o">=</span> <span class="n">content_image</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="c1"># or start from random image</span>
        <span class="c1"># input_image = torch.randn(</span>
        <span class="c1">#     content_image.data.size(), device=constants.DEVICE)</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_content_optimizer</span><span class="p">(</span><span class="n">input_image</span><span class="p">,</span> <span class="n">optt</span><span class="o">=</span><span class="n">optim</span><span class="o">.</span><span class="n">LBFGS</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">)):</span>
            <span class="k">def</span> <span class="nf">closure</span><span class="p">():</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="c1"># pass content image through net</span>
                <span class="bp">self</span><span class="p">(</span><span class="n">input_image</span><span class="p">,</span> <span class="n">content_image</span><span class="p">)</span>

                <span class="c1"># get losses</span>
                <span class="n">style_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_total_current_style_loss</span><span class="p">(</span>
                    <span class="n">weight</span><span class="o">=</span><span class="n">style_weight</span><span class="p">)</span>
                <span class="n">content_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_total_current_content_loss</span><span class="p">(</span>
                    <span class="n">weight</span><span class="o">=</span><span class="n">content_weight</span><span class="p">)</span>

                <span class="n">total_loss</span> <span class="o">=</span> <span class="n">style_loss</span> <span class="o">+</span> <span class="n">content_loss</span>
                <span class="n">total_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

                <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Loss: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">total_loss</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">input_image</span></div></div>


<div class="viewcode-block" id="ResidualBlock"><a class="viewcode-back" href="../../network_module.html#stransfer.network.ResidualBlock">[docs]</a><span class="k">class</span> <span class="nc">ResidualBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="c1"># based on the residual block implementation from:</span>
    <span class="c1"># https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/02-intermediate/deep_residual_network/main.py</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span>
                 <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
                               <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
                               <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
                               <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
                               <span class="n">padding</span><span class="o">=</span><span class="n">kernel_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                               <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;reflection&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">insn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
                               <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
                               <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
                               <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
                               <span class="n">padding</span><span class="o">=</span><span class="n">kernel_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                               <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;reflection&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">insn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<div class="viewcode-block" id="ResidualBlock.forward"><a class="viewcode-back" href="../../network_module.html#stransfer.network.ResidualBlock.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a tensor input, pass it through the residual block, and</span>
<span class="sd">        return the output.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># architecure of the residual block was taken from</span>
        <span class="c1"># Gross and Wilber (Training and investigating residual nets)</span>
        <span class="c1"># http://torch.ch/blog/2016/02/04/resnets.html</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">insn1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">+=</span> <span class="n">residual</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">insn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span></div></div>


<div class="viewcode-block" id="ImageTransformNet"><a class="viewcode-back" href="../../network_module.html#stransfer.network.ImageTransformNet">[docs]</a><span class="k">class</span> <span class="nc">ImageTransformNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This the implementation of the fast style transform, image transform</span>
<span class="sd">    network, as defined in:</span>

<span class="sd">    `Perceptual Losses for Real-Time Style Transfer and Super-Resolution &lt;https://arxiv.org/abs/1603.08155&gt;`_</span>

<span class="sd">    :param style_image: The image we want to use as as the style reference</span>
<span class="sd">    :param batch_size: the size of the batch</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">style_image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>

            <span class="c1"># Initial convolutional layers</span>
            <span class="c1"># First Conv</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                      <span class="n">out_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                      <span class="n">kernel_size</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
                      <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                      <span class="n">padding</span><span class="o">=</span><span class="mi">9</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                      <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;reflection&#39;</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>

            <span class="c1"># Second Conv</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                      <span class="n">out_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                      <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                      <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                      <span class="n">padding</span><span class="o">=</span><span class="mi">3</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                      <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;reflection&#39;</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>

            <span class="c1"># Third Conv</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                      <span class="n">out_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                      <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                      <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                      <span class="n">padding</span><span class="o">=</span><span class="mi">3</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                      <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;reflection&#39;</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>

            <span class="c1"># * Residual blocks</span>
            <span class="n">ResidualBlock</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                          <span class="n">out_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                          <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>

            <span class="n">ResidualBlock</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                          <span class="n">out_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                          <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>

            <span class="n">ResidualBlock</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                          <span class="n">out_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                          <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>

            <span class="n">ResidualBlock</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                          <span class="n">out_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                          <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>

            <span class="n">ResidualBlock</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                          <span class="n">out_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                          <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>

            <span class="c1"># Deconvolution layers</span>
            <span class="c1"># According to https://distill.pub/2016/deconv-checkerboard/</span>
            <span class="c1"># an upsampling layer followed by a convolution layer</span>
            <span class="c1"># yields better results</span>
            <span class="c1"># First &#39;deconvolution&#39; layer</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span>
                        <span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                      <span class="n">out_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                      <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                      <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                      <span class="n">padding</span><span class="o">=</span><span class="mi">3</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                      <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;reflection&#39;</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>

            <span class="c1"># Second &#39;deconvolution&#39; layer</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span>
                        <span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                      <span class="n">out_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                      <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                      <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                      <span class="n">padding</span><span class="o">=</span><span class="mi">3</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                      <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;reflection&#39;</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>

            <span class="c1"># * Final convolutional layer</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                      <span class="n">out_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                      <span class="n">kernel_size</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
                      <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                      <span class="n">padding</span><span class="o">=</span><span class="mi">9</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                      <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;reflection&#39;</span><span class="p">),</span>

        <span class="p">)</span>

        <span class="c1"># finally, set the style image which</span>
        <span class="c1"># transform network represents</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">style_image</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">),</span> <span class="s1">&#39;Style image need to be already loaded&#39;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">style_image</span> <span class="o">=</span> <span class="n">style_image</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>

<div class="viewcode-block" id="ImageTransformNet.get_total_variation_regularization_loss"><a class="viewcode-back" href="../../network_module.html#stransfer.network.ImageTransformNet.get_total_variation_regularization_loss">[docs]</a>    <span class="k">def</span> <span class="nf">get_total_variation_regularization_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                                <span class="n">transformed_image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                                                <span class="n">regularization_factor</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate a regularization loss, which will tell us how &#39;noisy&#39; is the current image.</span>
<span class="sd">        Penalize if it is very noisy.</span>
<span class="sd">        See: https://en.wikipedia.org/wiki/Total_variation_denoising#2D_signal_images</span>

<span class="sd">        :param transformed_image: image for which we will get the loss</span>
<span class="sd">        :param regularization_factor: &#39;weight&#39; to scale the loss</span>
<span class="sd">        :return: the regularization loss</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">regularization_factor</span> <span class="o">*</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span>
                    <span class="n">transformed_image</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">transformed_image</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">:])</span>
                <span class="p">)</span> <span class="o">+</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span>
                        <span class="n">transformed_image</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">transformed_image</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:])</span>
                <span class="p">))</span></div>

<div class="viewcode-block" id="ImageTransformNet.get_optimizer"><a class="viewcode-back" href="../../network_module.html#stransfer.network.ImageTransformNet.get_optimizer">[docs]</a>    <span class="k">def</span> <span class="nf">get_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get an initialized optimizer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">optimizer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span></div>

<div class="viewcode-block" id="ImageTransformNet.static_train"><a class="viewcode-back" href="../../network_module.html#stransfer.network.ImageTransformNet.static_train">[docs]</a>    <span class="k">def</span> <span class="nf">static_train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">style_name</span><span class="o">=</span><span class="s1">&#39;nsp&#39;</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                     <span class="n">style_weight</span><span class="o">=</span><span class="mi">100_000</span><span class="p">,</span> <span class="n">content_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains a fast style transfer network for style transfer on still images.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tb_writer</span> <span class="o">=</span> <span class="n">get_tensorboard_writer</span><span class="p">(</span>
            <span class="n">f</span><span class="s1">&#39;runs/fast-image-style-transfer-still-image_</span><span class="si">{style_name}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="c1"># TODO: try adding the following so that grads are not computed</span>
        <span class="c1"># with torch.no_grad():</span>
        <span class="n">loss_network</span> <span class="o">=</span> <span class="n">StyleNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">style_image</span><span class="p">,</span>
                                    <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                                        <span class="n">constants</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">))</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">)</span>

        <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Training network with &quot;</span><span class="si">%s</span><span class="s1">&quot; optimizer&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">optimizer</span><span class="p">))</span>

        <span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">test_loader</span><span class="p">,</span> <span class="n">train_loader</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_coco_loader</span><span class="p">(</span><span class="n">test_split</span><span class="o">=</span><span class="mf">0.10</span><span class="p">,</span>
                                                            <span class="n">test_limit</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                                                            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>

            <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Starting epoch </span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
            <span class="n">epoch_checkpoint_name</span> <span class="o">=</span> <span class="n">f</span><span class="s1">&#39;data/models/fast_st_</span><span class="si">{style_name}</span><span class="s1">_epoch</span><span class="si">{epoch}</span><span class="s1">.pth&#39;</span>

            <span class="c1"># if the checkpoint file for this epoch exists then we</span>
            <span class="c1"># just load it and go over to the next epoch</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">epoch_checkpoint_name</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
                    <span class="n">adaptive_torch_load</span><span class="p">(</span><span class="n">epoch_checkpoint_name</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="k">continue</span>

            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

                <span class="k">def</span> <span class="nf">closure</span><span class="p">():</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                    <span class="n">transformed_image</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

                    <span class="c1"># evaluate how good the transformation is</span>
                    <span class="n">loss_network</span><span class="p">(</span><span class="n">transformed_image</span><span class="p">,</span>
                                 <span class="n">content_image</span><span class="o">=</span><span class="n">batch</span><span class="p">)</span>

                    <span class="c1"># Get losses</span>
                    <span class="n">style_loss</span> <span class="o">=</span> <span class="n">loss_network</span><span class="o">.</span><span class="n">get_total_current_style_loss</span><span class="p">(</span>
                        <span class="n">weight</span><span class="o">=</span><span class="n">style_weight</span>
                    <span class="p">)</span>

                    <span class="c1"># Feature loss doesn&#39;t seem to be much better than the normal</span>
                    <span class="c1"># content loss</span>
                    <span class="c1"># feature_weight = 1</span>
                    <span class="c1"># feature_loss = loss_network.get_total_current_feature_loss(</span>
                    <span class="c1">#     weight=feature_weight</span>
                    <span class="c1"># )</span>

                    <span class="n">content_loss</span> <span class="o">=</span> <span class="n">loss_network</span><span class="o">.</span><span class="n">get_total_current_content_loss</span><span class="p">(</span>
                        <span class="n">weight</span><span class="o">=</span><span class="n">content_weight</span>
                    <span class="p">)</span>
                    <span class="n">regularization_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_total_variation_regularization_loss</span><span class="p">(</span>
                        <span class="n">transformed_image</span>
                    <span class="p">)</span>

                    <span class="c1"># calculate loss</span>
                    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">style_loss</span> <span class="o">+</span> <span class="n">content_loss</span> <span class="o">+</span> <span class="n">regularization_loss</span>

                    <span class="n">total_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

                    <span class="n">LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Max of each channel: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="p">[</span>
                        <span class="n">x</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">transformed_image</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()])</span>
                    <span class="n">LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Min of each channel: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="p">[</span>
                        <span class="n">x</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">transformed_image</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()])</span>
                    <span class="n">LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Sum of each channel: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="p">[</span>
                        <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">transformed_image</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()])</span>
                    <span class="n">LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Closure loss: </span><span class="si">%.8f</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">)</span>

                    <span class="k">return</span> <span class="n">total_loss</span>

                <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">closure</span><span class="p">()</span>

                    <span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                        <span class="s1">&#39;data/fst_train_loss&#39;</span><span class="p">,</span>
                        <span class="n">total_loss</span><span class="p">,</span>
                        <span class="n">iteration</span><span class="p">)</span>

                    <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Batch Loss: </span><span class="si">%.8f</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">150</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">average_test_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">static_test</span><span class="p">(</span>
                        <span class="n">test_loader</span><span class="p">,</span> <span class="n">loss_network</span><span class="p">)</span>

                    <span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                        <span class="s1">&#39;data/fst_test_loss&#39;</span><span class="p">,</span> <span class="n">average_test_loss</span><span class="p">,</span> <span class="n">iteration</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">transformed_image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span>
                        <span class="bp">self</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span>  <span class="c1"># transform the image</span>
                        <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="nb">max</span><span class="o">=</span><span class="mi">255</span>
                    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

                    <span class="n">tb_writer</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">&#39;data/fst_images&#39;</span><span class="p">,</span>
                                        <span class="n">img_utils</span><span class="o">.</span><span class="n">concat_images</span><span class="p">(</span>
                                            <span class="n">transformed_image</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
                                            <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()),</span>
                                        <span class="n">iteration</span><span class="p">)</span>
                <span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1"># after processing the batch, run the gradient update</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span>

            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="n">epoch_checkpoint_name</span>
            <span class="p">)</span></div>

<div class="viewcode-block" id="ImageTransformNet.static_test"><a class="viewcode-back" href="../../network_module.html#stransfer.network.ImageTransformNet.static_test">[docs]</a>    <span class="k">def</span> <span class="nf">static_test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">loss_network</span><span class="p">,</span> <span class="n">style_weight</span><span class="o">=</span><span class="mi">100_000</span><span class="p">,</span> <span class="n">feature_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Tests the performance of a fast style transfer network on still images</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">total_test_loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">test_batch</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
            <span class="n">transformed_image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span>
                <span class="bp">self</span><span class="p">(</span><span class="n">test_batch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span>  <span class="c1"># transfor the image</span>
                <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="nb">max</span><span class="o">=</span><span class="mi">255</span>
            <span class="p">)</span>

            <span class="n">loss_network</span><span class="p">(</span><span class="n">transformed_image</span><span class="p">,</span>
                         <span class="n">content_image</span><span class="o">=</span><span class="n">test_batch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

            <span class="n">style_loss</span> <span class="o">=</span> <span class="n">style_weight</span> <span class="o">*</span> <span class="n">loss_network</span><span class="o">.</span><span class="n">get_total_current_style_loss</span><span class="p">()</span>
            <span class="n">feature_loss</span> <span class="o">=</span> <span class="n">feature_weight</span> <span class="o">*</span> <span class="n">loss_network</span><span class="o">.</span><span class="n">get_total_current_feature_loss</span><span class="p">()</span>

            <span class="n">total_test_loss</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">style_loss</span> <span class="o">+</span> <span class="n">feature_loss</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="n">average_test_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">total_test_loss</span><span class="p">))</span>
        <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Average test loss: </span><span class="si">%.8f</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">average_test_loss</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">average_test_loss</span></div>

<div class="viewcode-block" id="ImageTransformNet.process_image"><a class="viewcode-back" href="../../network_module.html#stransfer.network.ImageTransformNet.process_image">[docs]</a>    <span class="k">def</span> <span class="nf">process_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">style_name</span><span class="o">=</span><span class="s1">&#39;nsp&#39;</span><span class="p">,</span> <span class="n">out_dir</span><span class="o">=</span><span class="s1">&#39;results/&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Processes a given input image at `image_path` with a network pretrained on the</span>
<span class="sd">        style `style_name`.</span>

<span class="sd">        Saves the processed image to `out_dir`</span>

<span class="sd">        :param image_path: path to the image we want to stylize</span>
<span class="sd">        :param style_name: name of the style we want to apply to the image. Note that a</span>
<span class="sd">            pretrained model with said style must exist in `data/models/`</span>
<span class="sd">        :param out_dir: directory were the stylized image will be saved</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># set weights to latest checkpoint</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
            <span class="n">_load_latest_model_weigths</span><span class="p">(</span>
                <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;fast_st&#39;</span><span class="p">,</span>
                <span class="n">style_name</span><span class="o">=</span><span class="n">style_name</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="n">input_image</span> <span class="o">=</span> <span class="n">img_utils</span><span class="o">.</span><span class="n">image_loader</span><span class="p">(</span>
            <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">constants</span><span class="o">.</span><span class="n">PROJECT_ROOT_PATH</span><span class="p">,</span> <span class="n">image_path</span><span class="p">))</span>

        <span class="c1"># transform the image</span>
        <span class="n">transformed_image</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span>

        <span class="c1"># save the image</span>
        <span class="n">out_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">constants</span><span class="o">.</span><span class="n">PROJECT_ROOT_PATH</span><span class="p">,</span> <span class="n">out_dir</span><span class="p">)</span>

        <span class="c1"># ensure that the result directory exist</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">out_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;converted_fast_st_</span><span class="si">{style_name}</span><span class="s1">.png&#39;</span><span class="p">)</span>
        <span class="n">img_utils</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">transformed_image</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="n">out_file</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="VideoTransformNet"><a class="viewcode-back" href="../../network_module.html#stransfer.network.VideoTransformNet">[docs]</a><span class="k">class</span> <span class="nc">VideoTransformNet</span><span class="p">(</span><span class="n">ImageTransformNet</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implementation of the video transform net.</span>

<span class="sd">    :param style_image: image we&#39;ll use as style reference</span>
<span class="sd">    :param batch_size: size of the batch</span>
<span class="sd">    :param fast_transfer_dict: state dict from a pretrained &#39;fast style network&#39;. It</span>
<span class="sd">        allows us to start training the video model from this, which allows to</span>
<span class="sd">        bootstrap training. It is recommended to do this since the current video set</span>
<span class="sd">        is not very big.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">style_image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">fast_transfer_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">style_image</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
                            <span class="n">out_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                            <span class="n">kernel_size</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
                            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">padding</span><span class="o">=</span><span class="mi">9</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                            <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;reflection&#39;</span><span class="p">)</span>

        <span class="c1"># since this video net is exactly the same as the ImageTransformNet</span>
        <span class="c1"># &#39;fast transfer&#39; then we can reuse it&#39;s backup weights, already trained</span>
        <span class="c1"># on imagenet, for this task.</span>
        <span class="k">if</span> <span class="n">fast_transfer_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># if &#39;fast_transfer_dict&#39; is a string then we take it to be the path</span>
            <span class="c1"># to a dump of the weights. So we load it.</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fast_transfer_dict</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">fast_transfer_dict</span> <span class="o">=</span> <span class="n">adaptive_torch_load</span><span class="p">(</span><span class="n">fast_transfer_dict</span><span class="p">)</span>

            <span class="c1"># but first we have to remove the &#39;weight&#39; and &#39;bias&#39; for the first layer,</span>
            <span class="c1"># since this is the one we will be replacing in this &#39;VideoTransformNet&#39;</span>
            <span class="k">del</span> <span class="n">fast_transfer_dict</span><span class="p">[</span><span class="s1">&#39;0.weight&#39;</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">fast_transfer_dict</span><span class="p">[</span><span class="s1">&#39;0.bias&#39;</span><span class="p">]</span>

            <span class="c1"># update video net state dict so that we ensure we have</span>
            <span class="c1"># the correct weight/biases for the first layer</span>
            <span class="n">m_sd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">m_sd</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">fast_transfer_dict</span><span class="p">)</span>

            <span class="c1"># finally load weights into network</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">m_sd</span><span class="p">)</span>

            <span class="c1"># flag to use when training, to know if we&#39;ve loaded</span>
            <span class="c1"># external weights or not</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">has_external_weights</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">has_external_weights</span> <span class="o">=</span> <span class="kc">False</span>

<div class="viewcode-block" id="VideoTransformNet.get_temporal_loss"><a class="viewcode-back" href="../../network_module.html#stransfer.network.VideoTransformNet.get_temporal_loss">[docs]</a>    <span class="k">def</span> <span class="nf">get_temporal_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">old_content</span><span class="p">,</span> <span class="n">old_stylized</span><span class="p">,</span>
                          <span class="n">current_content</span><span class="p">,</span> <span class="n">current_stylized</span><span class="p">,</span>
                          <span class="n">temporal_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the temporal loss</span>
<span class="sd">        See https://github.com/tupini07/StyleTransfer/issues/5</span>

<span class="sd">        :param old_content: tensor representing the content of the previous frame</span>
<span class="sd">        :param old_stylized: tensor representing the stylized previous frame</span>
<span class="sd">        :param current_content: tensor representing the content of the current frame</span>
<span class="sd">        :param current_stylized: tensor representing the stylized current frame</span>
<span class="sd">        :param temporal_weight: weight for the temporal loss</span>
<span class="sd">        :return: the temporal loss</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">change_in_style</span> <span class="o">=</span> <span class="p">(</span><span class="n">current_stylized</span> <span class="o">-</span> <span class="n">old_stylized</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
        <span class="n">change_in_content</span> <span class="o">=</span> <span class="p">(</span><span class="n">current_content</span> <span class="o">-</span> <span class="n">old_content</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">change_in_style</span> <span class="o">/</span> <span class="p">(</span><span class="n">change_in_content</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">temporal_weight</span></div>

<div class="viewcode-block" id="VideoTransformNet.video_train"><a class="viewcode-back" href="../../network_module.html#stransfer.network.VideoTransformNet.video_train">[docs]</a>    <span class="k">def</span> <span class="nf">video_train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">style_name</span><span class="o">=</span><span class="s1">&#39;nsp&#39;</span><span class="p">,</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">temporal_weight</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">style_weight</span><span class="o">=</span><span class="mi">100_000</span><span class="p">,</span>
                    <span class="n">feature_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">content_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains the video network</span>

<span class="sd">        :param style_name: the name of the style (used for saving and loading checkpoints)</span>
<span class="sd">        :param epochs: how many epochs should the training go through</span>
<span class="sd">        :param temporal_weight: the weight for the temporal loss</span>
<span class="sd">        :param style_weight: the weight for the style loss</span>
<span class="sd">        :param feature_weight: the weight for the feature loss</span>
<span class="sd">        :param content_weight: the weight for the content loss</span>
<span class="sd">        :return:</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">tb_writer</span> <span class="o">=</span> <span class="n">get_tensorboard_writer</span><span class="p">(</span>
            <span class="n">f</span><span class="s1">&#39;runs/video-style-transfer_</span><span class="si">{style_name}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="n">VIDEO_FOLDER</span> <span class="o">=</span> <span class="n">f</span><span class="s1">&#39;video_samples_</span><span class="si">{style_name}</span><span class="s1">/&#39;</span>
        <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">VIDEO_FOLDER</span><span class="p">,</span> <span class="n">ignore_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">VIDEO_FOLDER</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># TODO: try adding the following so that grads are not computed</span>
        <span class="c1"># with torch.no_grad():</span>
        <span class="n">style_loss_network</span> <span class="o">=</span> <span class="n">StyleNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">style_image</span><span class="p">,</span>
                                          <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                                              <span class="n">constants</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">))</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">)</span>
        <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Training video network with &quot;</span><span class="si">%s</span><span class="s1">&quot; optimizer&#39;</span><span class="p">,</span>
                    <span class="nb">type</span><span class="p">(</span><span class="n">optimizer</span><span class="p">))</span>
        <span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">video_loader</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">VideoDataset</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="c1"># we freeze the &#39;external_weights&#39; during the first epoch</span>
            <span class="c1"># if these are present</span>
            <span class="k">if</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_external_weights</span><span class="p">:</span>
                <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="s1">&#39;Freezing weights imported from fast transfer network for the first epoch&#39;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
                    <span class="c1"># all layers which are not the first one</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;0.&#39;</span><span class="p">):</span>
                        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="c1"># next epoch we just &#39;unfreeze&#39; all</span>
            <span class="k">if</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_external_weights</span><span class="p">:</span>
                <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Unfreezing all weights&#39;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="n">epoch_checkpoint_name</span> <span class="o">=</span> <span class="n">f</span><span class="s1">&#39;data/models/video_st_</span><span class="si">{style_name}</span><span class="s1">_epoch</span><span class="si">{epoch}</span><span class="s1">.pth&#39;</span>

            <span class="c1"># if the checkpoint file for this epoch exists then we</span>
            <span class="c1"># just load it and go over to the next epoch</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">epoch_checkpoint_name</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
                    <span class="n">adaptive_torch_load</span><span class="p">(</span><span class="n">epoch_checkpoint_name</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="k">continue</span>

            <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Starting epoch </span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">video_batch</span> <span class="ow">in</span> <span class="n">video_loader</span><span class="p">:</span>

                <span class="c1"># of shape [content, stylized]</span>
                <span class="n">old_images</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">iterate_on_video_batches</span><span class="p">(</span><span class="n">video_batch</span><span class="p">):</span>

                    <span class="c1"># if we&#39;re in new epoch then previous frame is None</span>
                    <span class="k">if</span> <span class="n">old_images</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">old_images</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch</span><span class="p">]</span>

                    <span class="c1"># ? make images available as simple vars</span>
                    <span class="n">old_content_images</span> <span class="o">=</span> <span class="n">old_images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">old_styled_images</span> <span class="o">=</span> <span class="n">old_images</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

                    <span class="n">batch_with_old_content</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">old_styled_images</span><span class="p">],</span>
                        <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                    <span class="k">def</span> <span class="nf">closure</span><span class="p">():</span>
                        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                        <span class="n">transformed_image</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">batch_with_old_content</span><span class="p">)</span>

                        <span class="n">style_loss_network</span><span class="p">(</span><span class="n">transformed_image</span><span class="p">,</span>
                                           <span class="n">content_image</span><span class="o">=</span><span class="n">batch</span><span class="p">)</span>

                        <span class="n">style_loss</span> <span class="o">=</span> <span class="n">style_loss_network</span><span class="o">.</span><span class="n">get_total_current_style_loss</span><span class="p">(</span>
                            <span class="n">weight</span><span class="o">=</span><span class="n">style_weight</span>
                        <span class="p">)</span>

                        <span class="c1"># feature weights don&#39;t seem to improve much the final results</span>
                        <span class="c1"># feature_loss = style_loss_network.get_total_current_feature_loss(</span>
                        <span class="c1">#     weight=feature_weight</span>
                        <span class="c1"># )</span>
                        <span class="n">content_loss</span> <span class="o">=</span> <span class="n">style_loss_network</span><span class="o">.</span><span class="n">get_total_current_content_loss</span><span class="p">(</span>
                            <span class="n">weight</span><span class="o">=</span><span class="n">content_weight</span>
                        <span class="p">)</span>
                        <span class="n">regularization_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_total_variation_regularization_loss</span><span class="p">(</span>
                            <span class="n">transformed_image</span>
                        <span class="p">)</span>

                        <span class="n">temporal_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_temporal_loss</span><span class="p">(</span>
                            <span class="n">old_content_images</span><span class="p">,</span>
                            <span class="n">old_styled_images</span><span class="p">,</span>
                            <span class="n">batch</span><span class="p">,</span>
                            <span class="n">transformed_image</span><span class="p">,</span>
                            <span class="n">temporal_weight</span><span class="o">=</span><span class="n">temporal_weight</span>
                        <span class="p">)</span>

                        <span class="c1"># * agregate losses</span>
                        <span class="n">total_loss</span> <span class="o">=</span> <span class="n">style_loss</span> <span class="o">+</span> <span class="n">content_loss</span> <span class="o">+</span> <span class="n">regularization_loss</span> <span class="o">+</span> <span class="n">temporal_loss</span>

                        <span class="c1"># * set old content and stylized versions</span>
                        <span class="n">old_images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
                        <span class="n">old_images</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">transformed_image</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

                        <span class="n">total_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

                        <span class="c1"># * debug messages</span>
                        <span class="n">LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Max of each channel: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="p">[</span>
                            <span class="n">x</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">transformed_image</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()])</span>
                        <span class="n">LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Min of each channel: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="p">[</span>
                            <span class="n">x</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">transformed_image</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()])</span>
                        <span class="n">LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Sum of each channel: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="p">[</span>
                            <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">transformed_image</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()])</span>
                        <span class="n">LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Closure loss: </span><span class="si">%.8f</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">)</span>

                        <span class="k">return</span> <span class="n">total_loss</span>

                    <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">total_loss</span> <span class="o">=</span> <span class="n">closure</span><span class="p">()</span>

                        <span class="n">tb_writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                            <span class="s1">&#39;data/fst_train_loss&#39;</span><span class="p">,</span>
                            <span class="n">total_loss</span><span class="p">,</span>
                            <span class="n">iteration</span><span class="p">)</span>
                        <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Epoch: </span><span class="si">%d</span><span class="se">\t</span><span class="s1">Batch Loss: </span><span class="si">%.4f</span><span class="s1">&#39;</span><span class="p">,</span>
                                    <span class="n">epoch</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">transformed_image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span>
                            <span class="bp">self</span><span class="p">(</span><span class="n">batch_with_old_content</span><span class="p">),</span>  <span class="c1"># transform the image</span>
                            <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                            <span class="nb">max</span><span class="o">=</span><span class="mi">255</span>
                        <span class="p">)[</span><span class="mi">2</span><span class="p">]</span>

                        <span class="n">tb_writer</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">&#39;data/fst_images&#39;</span><span class="p">,</span>
                                            <span class="n">img_utils</span><span class="o">.</span><span class="n">concat_images</span><span class="p">(</span>
                                                <span class="n">transformed_image</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
                                                <span class="n">batch</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()),</span>
                                            <span class="n">iteration</span><span class="p">)</span>
                    <span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>

                    <span class="c1"># after processing the batch, run the gradient update</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span>

            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="n">epoch_checkpoint_name</span>
            <span class="p">)</span></div>

<div class="viewcode-block" id="VideoTransformNet.process_video"><a class="viewcode-back" href="../../network_module.html#stransfer.network.VideoTransformNet.process_video">[docs]</a>    <span class="k">def</span> <span class="nf">process_video</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">video_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">style_name</span><span class="o">=</span><span class="s1">&#39;nsp&#39;</span><span class="p">,</span>
                      <span class="n">working_dir</span><span class="o">=</span><span class="s1">&#39;workdir/&#39;</span><span class="p">,</span>
                      <span class="n">out_dir</span><span class="o">=</span><span class="s1">&#39;results/&#39;</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mf">24.0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Applies style to a single video, using pretrained weights. Note that the</span>
<span class="sd">        weights must exist, if not an exception will be raised.</span>

<span class="sd">        :param video_path: the path of the video to stylize</span>
<span class="sd">        :param style_name: the name of the style to apply to the video. The weights for a video</span>
<span class="sd">            transform model using said style must exist in `data/models/`</span>
<span class="sd">        :param working_dir: directory where the transformed frames will be saved</span>
<span class="sd">        :param out_dir: directory where the final transformed video will be saved</span>
<span class="sd">        :param fps: the frames per second to use in the final video</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">video_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">constants</span><span class="o">.</span><span class="n">PROJECT_ROOT_PATH</span><span class="p">,</span> <span class="n">video_path</span><span class="p">)</span>
        <span class="n">working_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">constants</span><span class="o">.</span><span class="n">PROJECT_ROOT_PATH</span><span class="p">,</span> <span class="n">working_dir</span><span class="p">)</span>
        <span class="n">out_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">constants</span><span class="o">.</span><span class="n">PROJECT_ROOT_PATH</span><span class="p">,</span> <span class="n">out_dir</span><span class="p">)</span>

        <span class="c1"># set weights to latest checkpoint</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
            <span class="n">_load_latest_model_weigths</span><span class="p">(</span>
                <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;video_st&#39;</span><span class="p">,</span>
                <span class="n">style_name</span><span class="o">=</span><span class="n">style_name</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># we can treat this as a video batch of 1</span>
        <span class="n">video_reader</span> <span class="o">=</span> <span class="p">[</span><span class="n">imageio</span><span class="o">.</span><span class="n">get_reader</span><span class="p">(</span><span class="n">video_path</span><span class="p">)]</span>

        <span class="c1"># first we process each video frame, then we join those frames into</span>
        <span class="c1"># a final video</span>

        <span class="c1"># ensure that working_dir is empty</span>
        <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">working_dir</span><span class="p">,</span> <span class="n">ignore_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># ensure that the working and result directories exist</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">working_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># of shape [content, stylized]</span>
        <span class="n">old_image</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Starting to process video into stylized frames&#39;</span><span class="p">)</span>

        <span class="c1"># Stylize all frames separately</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">video_frame</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">iterate_on_video_batches</span><span class="p">(</span><span class="n">video_reader</span><span class="p">)):</span>

            <span class="c1"># if we&#39;re in new epoch then previous frame is None</span>
            <span class="k">if</span> <span class="n">old_image</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">old_image</span> <span class="o">=</span> <span class="n">video_frame</span>

            <span class="n">batch_with_old_content</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">video_frame</span><span class="p">,</span> <span class="n">old_image</span><span class="p">],</span>
                <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Get the transformed video image</span>
            <span class="n">transformed_image</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">batch_with_old_content</span><span class="p">)</span>

            <span class="c1"># set old image variable</span>
            <span class="n">old_image</span> <span class="o">=</span> <span class="n">transformed_image</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

            <span class="n">img_utils</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">transformed_image</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                             <span class="n">path</span><span class="o">=</span><span class="n">f</span><span class="s1">&#39;</span><span class="si">{working_dir}{i}</span><span class="s1">.png&#39;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;.. processing, currently frame </span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

        <span class="c1"># convert stylized frames into video</span>
        <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;All frames have been stylized.&#39;</span><span class="p">)</span>

        <span class="n">final_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;video_st_</span><span class="si">{style_name}</span><span class="s1">.mp4&#39;</span><span class="p">)</span>

        <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Joining stylized frames into a video&#39;</span><span class="p">)</span>

        <span class="n">video_writer</span> <span class="o">=</span> <span class="n">imageio</span><span class="o">.</span><span class="n">get_writer</span><span class="p">(</span><span class="n">final_path</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="n">fps</span><span class="p">)</span>

        <span class="n">frame_files</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
            <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">working_dir</span><span class="p">),</span>
            <span class="c1"># cast frame index to int when sorting so that we actually get</span>
            <span class="c1"># the correct order</span>
            <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">frame_name</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">frame_files</span><span class="p">):</span>
            <span class="n">video_writer</span><span class="o">.</span><span class="n">append_data</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">working_dir</span> <span class="o">+</span> <span class="n">frame_name</span><span class="p">)))</span>

        <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Done! Final stylized video can be found in: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">final_path</span><span class="p">)</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Andrea Tupini, Mario Berti

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>